{
  "applicationNumber": 18893643,
  "applicationId": "3DXS9H",
  "publicationNumber": "US20250099814A1",
  "rejections": [
    {
      "type": "35 U.S.C. 101",
      "claims": [
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12,
        13,
        14,
        15,
        16,
        17,
        18,
        19,
        20,
        21,
        22,
        23,
        24
      ],
      "priorArtReferences": [],
      "examinerReasoning": "Claims 1-24 are rejected under 35 U.S.C. 101 because the claimed invention is directed to a judicial exception (i.e., a law of nature, a natural phenomenon, or an abstract idea) without significantly more. The claimed invention is to a method (claim 1--8) and a computer devices (9-16) and computer readable media (17-24). Thus fall within one of the four statutory categories (Step 1: YES).\nClaims 1, 9 and 17 are directed to an electronic device in communication with one or more displays, and one or more input devices detecting, initiation of an associated exercise activity on a first view of the three-dimensional environment, presenting  a view of a physical environment to include a representation of the input exercise activity. A response to updating a presentation based on criteria of the representation are all steps  drawn to concept categorized as an actions that are  receiving, displaying, observing, identifying, evaluating and judging of various inputs. A concept that are mental processes and by including initiating of updating of exercise activity and processing of related information it becomes more like organizing of certain human activities. Comparison of first, second or other criteria may involve some mathematical calculations. But they all are generally categorized as a grouping of an abstract idea (Step 2A: Prong 1 Yes).\nThe independent claims do not include additional elements that are sufficient to be significantly more than the judicial exception because the limitations of “a computer system with interface display”, “a processor’, “a memory’, camera, databases of digital content with predetermined exercise activity environment”, “aggregation of input effects”, “criteria evaluation” are merely use of generic computer functions and computer parts. That is simply selecting portions of exercise activity representation and representing in accordance to input determination for updating or forgoing the presentation corresponds to filtering outputs for an evaluative sessions. Hence not indicative of integration of a practical application (Step 2A: Prong 2 No).\nThe steps in the recited claims that are highlighted are a well-understood, routine, and conventional activities known in art.  Figures  3A, 3B  of the instant specification depict tracking and recording object movements for a  hardware/ software  in a standard AR/VR environment with image panel implementing the process claimed here.   They are disclosed in their specification in a manner that indicates that those features are well-known, routine, and conventional. They are not dealing with actual improvements to, e.g., AR/VR, machine learning, etc. \nAs an  example in case of Versata Dev. Group, Inc. v. SAP Am., Inc., 793 F.3d 1306, 1334, 115 USPQ2d 1681, 1701 (Fed. Cir. 2015); OIP Techs., 788 F.3d at 1363, 115 USPQ2d at 1092-93, the activities of storing and retrieving of information in a memory of consumer electronic for a field of use purposes are recognized to be computer functions well-understood, routine, and conventional, when they are claimed in a merely generic manner. Further, there found to be no additional elements here in the claim recitation that improves the functioning of a computer itself to overcome the abstract idea rejection (Step 2B: No).\nThe dependent claims 2-8, 10-16, 18-24 describe additional limitations that serve only to modify and further describe the abstract idea. The representation of the exercise activity to include a representation of repetitions and that correspond to a completion, detection of activity or no activity and use of one or more input devices with a determination that the input satisfies one or more second criteria using one or more motion or orientation sensors \nThese are further description of elements not making abstract idea any less abstract. Any improvement in output display resulting from the claimed invention has nothing to do with the claimed computing devices, e.g., being able to run faster, use less power, and/or be manufactured more cheaply as a result of the invention.  Instead, the improvement, if there is one, is in terms of the applicant’s particular method for collecting data, analyzing data, and providing an output based on that analysis.  That is not a patent eligible improvement under AR/VR environment.\nThe all above dependent claims are merely an involvement of activities generally categorized as insignificant extra pre and post solution activity as that relates to an abstract idea of manipulating, monitoring, collection, comparison and outputting argument oriented text inputs. They are like in precedential case where court found there that the claims are also directed to monitoring, collection and comparison of data in electric grids but found to be abstract idea. (Step 2A: Prong 1 YES). The operation of the instant case is further based on generic computer processing of comparison, calculations and aggregation of information from components and peripherals such as from input devices, output interface and interactive network elements. There are sensors used. But all are operating under generic conditions. The recitations are not improving the functioning of a computer itself that could qualify this to be as significantly more (Step 2A: Prong 2 No). The courts have found such recognized computer functions to be well-understood, routine, and conventional functions when they are claimed in a merely generic manner (e.g., at a high level of generality) or as insignificant extra-solution activity. For example in receiving or transmitting data over a network, e.g., using the Internet to gather data, Symantec, 838 F.3d at 1321, 120 USPQ2d at 1362 i.e. utilizing an intermediary computer servers to forward information. All these elements are interpreted as part of generic computing device” or “system” as identified above to implement the abstract idea and thus not enough to qualify as significantly more. They do not improve the functionality of the computer or another technology (Step 2B: No).",
      "response": {
        "type": "other",
        "userResponse": "Recommend arguing without amendment as the primary strategy. The key argument is that the claims are directed to a technical improvement in computer functionality (XR user interfaces and sensor processing), not an abstract idea, citing Enfish/McRO. The specific use of optical sensors to analyze physical movements and automatically control a pass-through UI solves a technical problem inherent to XR devices. Likelihood of success is moderate to high. Strongly recommend requesting an Examiner Interview to present these arguments and demonstrate the technology, which should expedite allowance.",
        "finalizedAt": "2025-06-30T09:38:26.014Z"
      }
    },
    {
      "type": "35 U.S.C. 102",
      "claims": [
        1,
        2,
        3,
        4,
        5,
        6,
        11,
        15,
        18,
        19,
        20,
        22,
        23,
        24,
        27,
        39,
        40,
        41,
        42,
        43
      ],
      "priorArtReferences": [
        {
          "citedPubNo": "US20220101593",
          "citedPubURL": "https://patents.google.com/patent/US20220101593/en",
          "_id": "685f8efdce411fd3afe3da93"
        }
      ],
      "examinerReasoning": "Claim 1.   Rockel teaches a method comprising: at an electronic device in communication with one or more displays, and one or more input devices (Para 0002 computer systems with a display generation component and one or more input device): \ndetecting, using the one or more input devices (0006 detecting user inputs using input devices) including an optical sensor ( Para 0049 optical wave guide media), an initiation of an exercise activity associated with a user of the electronic device ( Para 0010 location associated with a first type of exercise activity on a first view of the three-dimensional environment includes a first representation of a first portion of a physical environment ); \npresenting, using the one or more displays, a view of a physical environment of the electronic device and a user interface that includes a representation of the exercise activity ( Fig.7D-7F  presenting display of a physical object representation relative to a viewpoint of a currently displayed view of a three-dimensional environment in different manners, where the viewpoint moves in accordance with movement of the user such as in exercise in a first physical environment); \nwhile presenting the user interface that includes the representation of the exercise activity, detecting, using the one or more input devices, an input ( Fig. 7N-7P selectively displaying virtual content presentation that corresponds to a respective type of exercise activity in a view of a detected three-dimensional environment corresponds to the respective type of exercise, changing a level of immersion or presentation on user interface in accordance with changing input biometric data of a user an input); and \nin response to detecting the input: \nin accordance with a determination that the input satisfies one or more first criteria, updating a presentation of the representation of the exercise activity in the user interface (Para 0035a adjustment aspects of a physical environment changes to better corresponds to the perceptive state of the user for the computer-generated experience i.e. when first user meets first criteria, the computer system displays the first computer-generated experience with another level of immersion,) ; and \nin accordance with a determination that the input does not satisfy the one or more first criteria, forgoing updating the presentation of the representation of the exercise activity in the user interface (Fig.7G; Para 0163 the biometric data of a user not meeting preset criteria corresponding to a next higher level of immersion, the computer system maintains display of the first view of the three-dimensional environment or forgo updating, without reducing visual prominence of the representation of the physical environment in the currently displayed view of the three-dimensional environment).  \n\nClaim 2. The method of claim 1, wherein the representation of the exercise activity includes a representation of repetitions of the exercise activity (Para 0213 repetitions of movement that corresponds to a type of exercise ).  \n\nClaim 3. The method of claim 1, wherein the one or more first criteria correspond to a completion of a repetition of the exercise activity (Para 0224 status information include number of repetitions completed) .  \n\nClaim 4. The method of claim 1, further comprising: detecting, using the one or more input devices including the optical sensor, a weight associated with the exercise activity (Para 0221  weight training machine).  \n\nClaim 5. The method of claim 1, further comprising: in accordance with a determination that the input satisfies one or more second criteria including a criterion that is satisfied when a set of repetitions of the exercise activity is complete, presenting a rest user interface; and in accordance with a determination that the input does not satisfy the one or more second criteria, forgoing presenting the rest user interface ( Para 0410 activity completion such as poses completion presented with progress information depending on input and criteria for the rest user interface ).  \n\nClaim 6. The method of claim 1, further comprising: detecting, using the one or more input devices, a second input; and in response to detecting the input: in accordance with a determination that the second input satisfies one or more fourth criteria including a criterion that is satisfied when a second exercise activity different than the exercise activity is detected, presenting a user interface including a representation of the second exercise activity (Figure 7OB element 7408 second view as an augmented reality view displayed with a higher-level of immersion e.g., displaying user interface objects in a second input different from part of a first specific application experience; Para 0359 a fourth representation of a first portion) .  \n\nClaim 7. The method of claim 1, wherein detecting the initiation of the exercise activity further includes detecting a movement consistent with exercise using one or more motion or orientation sensors (Para 0039 motion sensors), the method further comprising: after detecting the initiation of the exercise activity, detecting, using the one or more input devices including the optical sensor and a microphone, a type of exercise activity (Para 0049 optical sensors and microphones).  \n\nClaim 8. The method of claim 1, further comprising: in accordance with a determination that the input satisfies one or more second criteria, including a criterion that is satisfied when an exercise activity is no longer detected, presenting a rest user interface that accounts for a disambiguation period, wherein the rest user interface is presented after the disambiguation period (Para 0157 level of disambiguation and clarity levels are accounted).  \n\nClaim 9. An electronic device comprising: a display; a memory; one or more displays; one or more input devices; one or more processors; and one or more programs stored in the memory and configured to be executed by the one or more processors, the one or more programs including instructions for: \ndetecting, using the one or more input devices (0006 detecting user inputs using input devices) including an optical sensor ( Para 0049 optical wave guide media), an initiation of an exercise activity associated with a user of the electronic device ( Para 0010 location associated with a first type of exercise activity on a first view of the three-dimensional environment includes a first representation of a first portion of a physical environment ); \npresenting, using the one or more displays, a view of a physical environment of the electronic device and a user interface that includes a representation of the exercise activity ( Fig.7D-7F  presenting display of a physical object representation relative to a viewpoint of a currently displayed view of a three-dimensional environment in different manners, where the viewpoint moves in accordance with movement of the user such as in exercise in a first physical environment); \nwhile presenting the user interface that includes the representation of the exercise activity, detecting, using the one or more input devices, an input ( Fig. 7N-7P selectively displaying virtual content presentation that corresponds to a respective type of exercise activity in a view of a detected three-dimensional environment corresponds to the respective type of exercise, changing a level of immersion or presentation on user interface in accordance with changing input biometric data of a user an input); and \nin response to detecting the input:\nin accordance with a determination that the input satisfies one or more first criteria, updating a presentation of the representation of the exercise activity in the user interface (Para 0035a adjustment aspects of a physical environment changes to better corresponds to the perceptive state of the user for the computer-generated experience i.e. when first user meets first criteria, the computer system displays the first computer-generated experience with another level of immersion,) ; and \nin accordance with a determination that the input does not satisfy the one or more first criteria, forgoing updating the presentation of the representation of the exercise activity in the user interface (Fig.7G; Para 0163 the biometric data of a user not meeting preset criteria corresponding to a next higher level of immersion, the computer system maintains display of the first view of the three-dimensional environment or forgo updating, without reducing visual prominence of the representation of the physical environment in the currently displayed view of the three-dimensional environment).  \n\nClaim 10. The electronic device of claim 9, wherein the representation of the exercise activity includes a representation of repetitions of the exercise activity (Para 0213 repetitions of movement that corresponds to a type of exercise ).  \n\nClaim 11. The electronic device of claim 9, wherein the one or more first criteria correspond to a completion of a repetition of the exercise activity (Para 0224 status information include number of repetitions completed) .  \n  \nClaim 12. The electronic device of claim 9, wherein the one or more programs including instructions for: detecting, using the one or more input devices including the optical sensor, a weight associated with the exercise activity (Para 0221  weight training machine).  \n  \nClaim 13. The electronic device of claim 9, wherein the one or more programs including instructions for: in accordance with a determination that the input satisfies one or more second criteria including a criterion that is satisfied when a set of repetitions of the exercise activity is complete, presenting a rest user interface; and in accordance with a determination that the input does not satisfy the one or more second criteria, forgoing presenting the rest user interface ( Para 0410 activity completion such as poses completion presented with progress information depending on input and criteria for the rest user interface ).  \n\nClaim 14. The electronic device of claim 9, wherein the one or more programs including instructions for: detecting, using the one or more input devices, a second input; and in response to detecting the input: in accordance with a determination that the second input satisfies one or more fourth criteria including a criterion that is satisfied when a second exercise activity different than the exercise activity is detected, presenting a user interface including a representation of the second exercise activity (Figure 7OB element 7408 second view as an augmented reality view displayed with a higher-level of immersion e.g., displaying user interface objects in a second input different from part of a first specific application experience; Para 0359 a fourth representation of a first portion)) .  \n  \n\nClaim 15. The electronic device of claim 9, wherein detecting the initiation of the exercise activity further includes detecting a movement consistent with exercise using one or more motion or orientation sensors; and after detecting the initiation of the exercise activity, detecting, using the one or more input devices including the optical sensor and a microphone, a type of exercise activity (Para 0049 optical sensors and microphones).  \n\nClaim 16. The electronic device of claim 9, further comprising: in accordance with a determination that the input satisfies one or more second criteria including a criterion that is satisfied when an exercise activity is no longer detected; presenting a rest user interface that accounts for a disambiguation period, wherein the rest user interface is presented after the disambiguation period (Para 0157 level of disambiguation and clarity levels are accounted).  \n  \nClaim 17. A non-transitory computer readable storage medium storing one or more programs, the one or more programs comprising instructions, which when executed by one or more processors of an electronic device, cause the electronic device to perform a method comprising: \ndetecting, using the one or more input devices (0006 detecting user inputs using input devices) including an optical sensor ( Para 0049 optical wave guide media), an initiation of an exercise activity associated with a user of the electronic device ( Para 0010 location associated with a first type of exercise activity on a first view of the three-dimensional environment includes a first representation of a first portion of a physical environment ); \npresenting, using the one or more displays, a view of a physical environment of the electronic device and a user interface that includes a representation of the exercise activity ( Fig.7D-7F  presenting display of a physical object representation relative to a viewpoint of a currently displayed view of a three-dimensional environment in different manners, where the viewpoint moves in accordance with movement of the user such as in exercise in a first physical environment); \nwhile presenting the user interface that includes the representation of the exercise activity, detecting, using the one or more input devices, an input ( Fig. 7N-7P selectively displaying virtual content presentation that corresponds to a respective type of exercise activity in a view of a detected three-dimensional environment corresponds to the respective type of exercise, changing a level of immersion or presentation on user interface in accordance with changing input biometric data of a user an input); and \nin response to detecting the input:\nin accordance with a determination that the input satisfies one or more first criteria, updating a presentation of the representation of the exercise activity in the user interface (Para 0035a adjustment aspects of a physical environment changes to better corresponds to the perceptive state of the user for the computer-generated experience i.e. when first user meets first criteria, the computer system displays the first computer-generated experience with another level of immersion,) ; and \nin accordance with a determination that the input does not satisfy the one or more first criteria, forgoing updating the presentation of the representation of the exercise activity in the user interface (Fig.7G; Para 0163 the biometric data of a user not meeting preset criteria corresponding to a next higher level of immersion, the computer system maintains display of the first view of the three-dimensional environment or forgo updating, without reducing visual prominence of the representation of the physical environment in the currently displayed view of the three-dimensional environment).  \n\nClaim 18. The non-transitory computer readable storage medium of claim 17, wherein the representation of the exercise activity includes a representation of repetitions of the exercise activity (Para 0213 repetitions of movement that corresponds to a type of exercise  ).  \n  \nClaim 19. The non-transitory computer readable storage medium of claim 17, wherein the one or more first criteria correspond to a completion of a repetition of the exercise activity (Para 0224 status information include number of repetitions completed) .  \n  \n20. The non-transitory computer readable storage medium of claim 17, further comprising: detecting, using the one or more input devices including the optical sensor, a weight associated with the exercise activity (Para 0221  weight training machine).\n. \nClaim 21. The non-transitory computer readable storage medium of claim 17, further comprising: in accordance with a determination that the input satisfies one or more second criteria including a criterion that is satisfied when a set of repetitions of the exercise activity is complete, presenting a rest user interface; and in accordance with a determination that the input does not satisfy the one or more second criteria, forgoing presenting the rest user interface ( Para 0410 activity completion such as poses completion presented with progress information depending on input and criteria for the rest user interface).  \n\nClaim 22. The non-transitory computer readable storage medium of claim 17, further comprising: detecting, using the one or more input devices, a second input; and in response to detecting the input: in accordance with a determination that the second input satisfies one or more fourth criteria including a criterion that is satisfied when a second exercise activity different than the exercise activity is detected, presenting a user interface including a representation of the second exercise activity (Figure 7OB element 7408 second view as an augmented reality view displayed with a higher-level of immersion e.g., displaying user interface objects in a second input different from part of a first specific application experience; Para 0359 a fourth representation of a first portion) .  \n  \nClaim 23. The non-transitory computer readable storage medium of claim 17, wherein detecting the initiation of the exercise activity further includes detecting a movement consistent with exercise using one or more motion or orientation sensors; the method further comprising: after detecting the initiation of the exercise activity, detecting, using the one or more input devices including the optical sensor and a microphone, a type of exercise activity (Para 0049 optical sensors and microphones).    \n\nClaim 24. The non-transitory computer readable storage medium of claim 17, further comprising: in accordance with a determination that the input satisfies one or more second criteria including a criterion that is satisfied when an exercise activity is no longer detected; presenting a rest user interface that accounts for a disambiguation period, wherein the rest user interface is presented after the disambiguation period (Para 0157 level of disambiguation and clarity levels are accounted).",
      "response": {
        "type": "dependentClaims",
        "amendedClaim": {
          "preamble": "A method comprising:\n at an electronic device in communication with one or more displays, and one or more input devices:",
          "elements": [
            {
              "elementId": "(a)",
              "text": "detecting, using the one or more input devices including an optical sensor, an initiation of an exercise activity associated with a user of the electronic device;",
              "_id": "685f8f92ce411fd3afe3daf9"
            },
            {
              "elementId": "(b)",
              "text": "presenting, using the one or more displays, a view of a physical environment of the electronic device and a user interface that includes a representation of repetitions of the exercise activity;",
              "_id": "685f8f92ce411fd3afe3dafa"
            },
            {
              "elementId": "(c)",
              "text": "while presenting the user interface that includes the representation of the repetitions of the exercise activity, detecting, using the one or more input devices, an input; and",
              "_id": "685f8f92ce411fd3afe3dafb"
            },
            {
              "elementId": "(d)",
              "text": "in response to detecting the input:\n  in accordance with a determination that the input satisfies one or more first criteria, wherein the one or more first criteria correspond to a completion of a repetition of the exercise activity, updating a presentation of the representation of the repetitions of the exercise activity in the user interface; and\n  in accordance with a determination that the input does not satisfy the one or more first criteria, forgoing updating the presentation of the representation of the repetitions of the exercise activity in the user interface.",
              "_id": "685f8f92ce411fd3afe3dafc"
            }
          ],
          "additionalElements": []
        },
        "comparisonTable": [
          {
            "featureNumber": 1,
            "subjectApplication": "Criteria are based on completing a physical repetition of the exercise, such as achieving a specific skeletal pose or range of motion [FIGS. 3C, 3K].",
            "priorArt": "Rockel's criteria are based on the user's physiological state (biometric data) meeting a threshold to change the environment's immersion level [Para 0035a, 0163].",
            "differentiatingFeature": "The distinction is between biomechanical movement validation for performance tracking versus physiological state monitoring for ambiance adjustment, which are technically distinct goals.",
            "_id": "685f8f92ce411fd3afe3daf5"
          },
          {
            "featureNumber": 2,
            "subjectApplication": "Updating a quantitative representation of *repetitions* of the exercise, such as incrementing a numerical counter in the user interface [FIG. 3B, Indication 320b].",
            "priorArt": "Rockel updates the entire computer-generated experience to a different *level of immersion*, a qualitative environmental change, not a specific quantitative data update [Para 0035a].",
            "differentiatingFeature": "A specific, quantitative update to a repetition count is not taught by Rockel's general, qualitative change in environmental immersion. The functions are fundamentally different.",
            "_id": "685f8f92ce411fd3afe3daf6"
          },
          {
            "featureNumber": 3,
            "subjectApplication": "Actively forgoing an update to the repetition count in response to an improper or incomplete movement, providing implicit feedback on exercise form [FIG. 3C].",
            "priorArt": "Rockel forgoes updating by passively maintaining the current immersion level when biometric criteria are not met, not as a response to an invalid user action [Para 0163].",
            "differentiatingFeature": "Our active decision not to credit an invalid rep is a specific feedback mechanism for form correction, a concept not taught or suggested by Rockel's system.",
            "_id": "685f8f92ce411fd3afe3daf7"
          },
          {
            "featureNumber": 4,
            "subjectApplication": "Detecting the specific weight associated with an exercise activity using an optical sensor and displaying it as part of the exercise representation [FIGS. 3A, 3L-M].",
            "priorArt": "Rockel mentions a 'weight training machine' in a list of examples but provides no teaching of optically detecting and tracking the specific weight value being used [Para 0221].",
            "differentiatingFeature": "The specific capability to optically recognize and integrate the exact weight into the tracking UI is a concrete technical feature absent from Rockel's high-level disclosure.",
            "_id": "685f8f92ce411fd3afe3daf8"
          }
        ],
        "amendmentStrategy": "The amendments distinguish over Rockel by adding specificity that is absent from the prior art, without unduly narrowing the claim. (1) The claim is amended to clarify that the 'representation' and 'update' pertain specifically to 'repetitions' of the exercise activity. This focuses the invention on quantitative tracking, unlike Rockel's qualitative immersion changes. (2) A 'wherein' clause is added to specify that the 'criteria' correspond to the 'completion of a repetition'. This clarifies that the criteria are biomechanical (related to movement form), directly contrasting with Rockel's physiological (biometric) criteria. (3) These amendments maintain broad scope by applying to any repetition-based exercise, not a specific one. (4) The amendments are fully supported by the original specification (e.g., FIGS. 3B-3C, 3I-K) and draw from the substance of original dependent claims 2 and 3, avoiding any new matter or 112 issues.",
        "finalizedAt": "2025-06-28T07:14:03.959Z"
      }
    }
  ],
  "dateGenerated": "2025-06-30T10:02:31.061Z"
}